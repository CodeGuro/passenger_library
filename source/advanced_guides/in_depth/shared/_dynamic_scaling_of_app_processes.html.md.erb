<h1>How dynamic scaling of <%= language_name %> application processes works</h1>

<p class="lead">Passenger <a href="<%= url_for "/config/#{integration_mode_type}/dynamic_scaling_vs_fixed_app_processes/index.html" %>">dynamically adjusts the number of application processes based on traffic</a>. Learn how Passenger decides when a process should be added or removed.</p>

**Table of contents**

<ol class="toc-container"><li>Loading...</li></ol>

## Maximum process concurrency

_Main article: [Request load balancing](<%= url_for "/indepth/#{language_type}/request_load_balancing.html" %>)_

A core concept in dynamic process scaling is that of the **maximum process concurrency**. This is the maximum number of concurrent requests that a particular process can handle.

<% if language_default_concurrency == 1 && language_max_concurrency == 0 %>
  For <%= language_name %> applications, the maximum process concurrency is assumed to be 1. This means that Passenger assumes each process can handle 1 request at a time.

  This can be changed by setting <%= link_to_config_option(:concurrency_model, locals) %> to `thread`, and by setting <%= link_to_config_option(:thread_count, locals) %>. If you do that, the assumed maximum process concurrency will equal the number of configured threads. This reflects the fact that each thread can handle 1 request at a time.
<% elsif language_default_concurrency == 1 && language_max_concurrency == 1 %>
  For <%= language_name %> applications, the maximum process concurrency is always 1.
<% elsif language_default_concurrency == 0 %>
  For <%= language_name %> applications, the maximum process concurrency is assumed to be *unlimited*. This is because <%= language_runtime_name %> uses <%= language_concurrency_model_name_plural %> for concurrency which is very lightweight, so it can handle a virtually unlimited number of requests concurrently.

  <% if language_concurrency_model == :evented %>
  Having said that, as a <%= language_runtime_name %> process handles more concurrent requests, it is normal for performance to degrade. The practical concurrency is not really unlimited, and the limit varies for every application and every workload.
  <% end %>
<% else %>
  <% raise "Unknown concurrency scenario: language_default_concurrency=#{language_default_concurrency}, language_max_concurrency=#{language_max_concurrency}" %>
<% end %>

<% if language_concurrency_model == :evented %>
  For dynamic process scaling to work, Passenger needs to [know at approximately how many requests the performance of a single process begins to degrade](<%= url_for_config_option(:force_max_concurrent_requests_per_process, locals) %>). You will learn later why this is so and how this is done.
<% end %>

## A new process is spawned when the concurrency limit is reached

Passenger keeps track of the number of requests a process is handling. When all processes have reached their maximum concurrency -- that is, when they're handling exactly as many requests as their maximum concurrency indicate they can -- then Passenger will decide to spawn a new process.

This behavior is deeply coupled to the [request load balancing logic](<%= url_for "/indepth/#{language_type}/request_load_balancing.html" %>), so you should read up on that too.

<% if language_default_concurrency == 0 %>
  <h3>Making dynamic scaling work by providing a hint to Passenger</h3>

  Since <%= language_name %> applications are assumed to have unlimited concurrency by default, _dynamic process scaling does not work out-of-the-box_. Passenger will never think that your application process has reached its maximum concurrency. This is why you need to give Passenger a hint: you need to tell Passenger how many concurrent requests your application can handle without degrading performance. This way, Passenger will know when it should spawn more processes.

  This is achieved with the configuration option <%= link_to_config_option(:force_max_concurrent_requests_per_process, locals) %>. For example, to tell Passenger that your application can handle at most 150 concurrent requests without degrading performance, set that option to 150. That way, Passenger will spawn more processes when all existing processes have reached 150 concurrent requests.

### Example: maximum concurrency of 4

Suppose that you have 2 application processes,
<% if language_concurrency_model == :thread -%>
  and you configured the number of threads to 4, causing each process's maximum concurrency to be 4.
<% else -%>
  and the processes' maximum concurrency is configured to 4.
<% end -%>
When the application is idle, none of the processes are handling any requests:

    Process A [    ]
    Process B [    ]

When a new request comes in, Passenger may decide to route the request to process A.

    Process A [*   ]
    Process B [    ]

Suppose that, while that request is still in progress, 7 more requests come in. All processes will reach their maximum concurrency:

    Process A [****]
    Process B [****]

If *another* request comes in, none of the existing processes have enough concurrency to handle that. So Passenger will queue the request and spawn a new process:

    Request queue [*       ]

    Process A [****]
    Process B [****]
    Process C (spawning...)

When process C is done spawning, or when one of the existing processes is done with their request (and are no longer at their maximum concurrency), then Passenger will route the queued request to either of those processes.

Suppose C finishes spawning immediately after, then the situation looks like this:

    Request queue [        ]
                       |
    Process A [****]   | queued request
    Process B [****]   | is routed to C
    Process C [*   ] <-+

<% elsif language_max_concurrency != 1 %>
### Example: maximum concurrency of 1

Suppose that you have 3 application processes, and each process's maximum concurrency is 1. When the application is idle, none of the processes are handling any requests:

    Process A [ ]
    Process B [ ]
    Process C [ ]

When a new request comes in, Passenger may decide to route the request to process A. Now A has reached its maximum concurrency:

    Process A [*]
    Process B [ ]
    Process C [ ]

Suppose that, while that request is still in progress, two new requests come in. Because A has reached its maximum concurrency, Passenger routes these two new requests to B and C. Now all requests have reached their maximum concurrency:

    Process A [*]
    Process B [*]
    Process C [*]

If a new request comes in while all previous 3 requests are still in progress, then Passenger will decide to spawn a new process. This new incoming request is put in a queue:

    Request queue [*       ]

    Process A [*]
    Process B [*]
    Process C [*]
    Process D (spawning...)

When process D is done spawning, or when one of the existing processes is done with their request (and are no longer at their maximum concurrency), then Passenger will route the queued request to either of those processes.

Suppose D finishes spawning immediately after, then the situation looks like this:

    Request queue [        ]
                    |
    Process A [*]   |
    Process B [*]   |  queued request
    Process C [*]   |  is routed to D
    Process D [*] <-+

### Example: maximum concurrency of 4

Suppose that you have 2 application processes,
<% if language_concurrency_model == :thread -%>
  and you configured the number of threads to 4, causing each process's maximum concurrency to be 4.
<% else -%>
  and the processes' maximum concurrency is configured to 4.
<% end -%>
When the application is idle, none of the processes are handling any requests:

    Process A [    ]
    Process B [    ]

When a new request comes in, Passenger may decide to route the request to process A.

    Process A [*   ]
    Process B [    ]

Suppose that, while that request is still in progress, 7 more requests come in. All processes will reach their maximum concurrency:

    Process A [****]
    Process B [****]

If *another* request comes in, none of the existing processes have enough concurrency to handle that. So Passenger will queue the request and spawn a new process:

    Request queue [*       ]

    Process A [****]
    Process B [****]
    Process C (spawning...)

When process C is done spawning, or when one of the existing processes is done with their request (and are no longer at their maximum concurrency), then Passenger will route the queued request to either of those processes.

Suppose C finishes spawning immediately after, then the situation looks like this:

    Request queue [        ]
                       |
    Process A [****]   | queued request
    Process B [****]   | is routed to C
    Process C [*   ] <-+

<% else %>
### Example: maximum concurrency of 1

Suppose that you have 3 application processes, and each process's maximum concurrency is 1. When the application is idle, none of the processes are handling any requests:

    Process A [ ]
    Process B [ ]
    Process C [ ]

When a new request comes in, Passenger may decide to route the request to process A. Now A has reached its maximum concurrency:

    Process A [*]
    Process B [ ]
    Process C [ ]

Suppose that, while that request is still in progress, two new requests come in. Because A has reached its maximum concurrency, Passenger routes these two new requests to B and C. Now all requests have reached their maximum concurrency:

    Process A [*]
    Process B [*]
    Process C [*]

If a new request comes in while all previous 3 requests are still in progress, then Passenger will decide to spawn a new process. This new incoming request is put in a queue:

    Request queue [*       ]

    Process A [*]
    Process B [*]
    Process C [*]
    Process D (spawning...)

When process D is done spawning, or when one of the existing processes is done with their request (and are no longer at their maximum concurrency), then Passenger will route the queued request to either of those processes.

Suppose D finishes spawning immediately after, then the situation looks like this:

    Request queue [        ]
                    |
    Process A [*]   |
    Process B [*]   |  queued request
    Process C [*]   |  is routed to D
    Process D [*] <-+

<% end %>

## A process is shut down when it becomes idle

When a process hasn't processed any requests for [a while](<%= url_for_config_option(:pool_idle_time, locals) %>), it is said to be "idle". Idle processes are shut down in order to conserve resources during periods of low traffic.

## Process limits

The minimum and maximum amount of processes depend on various configuration options, such as <%= link_to_config_option(:max_pool_size, locals) %>,
<% if integration_mode_type != :standalone -%>
  <%= link_to_config_option(:min_instances, locals) %> and <%= link_to_config_option(:max_instances, locals) %>.
<% else -%>
  and <%= link_to_config_option(:min_instances, locals) %>.
<% end -%>
Passenger won't ever scale the number of processes past the limits set by those configuration options.

## Disabling dynamic process scaling

You can disable dynamic process scaling by setting <%= link_to_config_option(:min_instances, locals) %> and <%= link_to_config_option(:max_instances, locals) %> to the same number. The advantage of this is that it will make your server a bit faster, because process spawning is expensive. The disadvantage is that Passenger will not be able to free up processes in order to conserve resources during times of low traffic.

## See also

 * [Request load balancing](<%= url_for "/indepth/#{language_type}/request_load_balancing.html" %>)
 * [Request queueing](<%= url_for "/indepth/request_queueing.html" %>)
 * [Dynamic scaling of application processes vs fixed process pool](<%= url_for "/config/#{integration_mode_type}/dynamic_scaling_vs_fixed_app_processes/index.html" %>)

<div class="back-button">
  <a class="dark-button" href="<%= url_for "/advanced_guides/in_depth/index.html" %>">Back</a>
</div>
